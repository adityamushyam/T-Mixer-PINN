{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmV85bTNhhRm",
        "outputId": "56f27e55-1e30-4bbe-9665-19585d045c20"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from smt.sampling_methods import LHS\n",
        "import torch              \n",
        "import torch.nn as nn                                   \n",
        "from collections import OrderedDict\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-snmJWSEhhRo",
        "outputId": "e738cc4f-5093-4215-a38f-3ba3f3bf908e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# CUDA GPU selection\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "W1aKhh0khhRq"
      },
      "outputs": [],
      "source": [
        "# Definition of Deep Neural Network Architecture\n",
        "class DNNModel(torch.nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,output_size,depth,act=torch.nn.Tanh,init_mode='xavier'):\n",
        "        super(DNNModel, self).__init__()\n",
        "        \n",
        "        layers = [('input', torch.nn.Linear(input_size, hidden_size))]\n",
        "        layers.append(('input_activation', act()))\n",
        "        for i in range(depth): \n",
        "            layers.append(\n",
        "                ('hidden_%d' % i, torch.nn.Linear(hidden_size, hidden_size))\n",
        "            )\n",
        "            layers.append(('activation_%d' % i, act()))\n",
        "        layers.append(('output', torch.nn.Linear(hidden_size, output_size)))\n",
        "\n",
        "        layerDict = OrderedDict(layers)\n",
        "        self.layers = torch.nn.Sequential(layerDict)\n",
        "\n",
        "        if init_mode == 'xavier':\n",
        "          for m in self.modules():                \n",
        "              if isinstance(m, nn.Linear):\n",
        "                  size = m.weight.size()\n",
        "                  fan_out = size[0] # Number of rows\n",
        "                  fan_in = size[1] # Number of columns\n",
        "                  variance = math.sqrt(2.0/(fan_in+fan_out))\n",
        "                  m.weight.data.normal_(0.0, variance)\n",
        "                  if m.bias is not None:\n",
        "                    m.bias.data.normal_(0, variance)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "hTjuYjs-hhRs"
      },
      "outputs": [],
      "source": [
        "# Defintion of Physics infomed neural network\n",
        "class PINN():\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.model = DNNModel(\n",
        "            input_size=2,\n",
        "            hidden_size=50,\n",
        "            output_size=5,\n",
        "            depth=8,\n",
        "            act=torch.nn.Tanh,\n",
        "            init_mode='xavier'\n",
        "            ).to(device)\n",
        "        \n",
        "        self.dx = 0.01        \n",
        "        self.dy = 0.005\n",
        "        self.dx1 = 0.005\n",
        "        self.dy1 = 0.01\n",
        "\n",
        "        self.nx = 300\n",
        "        self.ny = 200\n",
        "        self.nx1 = 200\n",
        "        self.ny1 = 100\n",
        "        self.nx2 = 100\n",
        "        \n",
        "        self.rho=1.1644\n",
        "        self.mu=0.005        \n",
        "      \n",
        "        # Bounday collocation points\n",
        "        xb = torch.arange(0, 3 + self.dx, self.dx)        \n",
        "\n",
        "        xu1 = torch.arange(0, 1 + self.dx, self.dx)      \n",
        "\n",
        "        xu2 = torch.arange(2, 3 + self.dx, self.dx)  \n",
        "\n",
        "        yb = torch.arange(0, 1 + self.dy, self.dy) \n",
        "\n",
        "        xb1 = torch.arange(1, 2 + self.dx1, self.dx1)\n",
        "\n",
        "        yb1 = torch.arange(1, 2 + self.dy1, self.dy1) \n",
        "\n",
        "        # Boundary discretization\n",
        "        self.inlet=torch.stack(torch.meshgrid(torch.zeros(1), yb)).reshape(2, -1).T\n",
        "        self.inlet1=torch.stack(torch.meshgrid(torch.ones(1)*3, yb)).reshape(2, -1).T\n",
        "        \n",
        "        self.outlet=torch.stack(torch.meshgrid(xb1, torch.ones(1)*2)).reshape(2, -1).T\n",
        "        \n",
        "        bc1 = torch.stack(torch.meshgrid(xb, torch.zeros(1))).reshape(2, -1).T\n",
        "        bc2 = torch.stack(torch.meshgrid(xu1, torch.ones(1))).reshape(2, -1).T\n",
        "        bc3 = torch.stack(torch.meshgrid(xu2, torch.ones(1))).reshape(2, -1).T\n",
        "        bc4 = torch.stack(torch.meshgrid(torch.ones(1), yb1)).reshape(2, -1).T\n",
        "        bc5 = torch.stack(torch.meshgrid(torch.ones(1)*2, yb1)).reshape(2, -1).T\n",
        "\n",
        "        self.bc = torch.cat([bc1, bc2, bc3, bc4, bc5])\n",
        "        \n",
        "        # Domain collocation points\n",
        "        xlimits = np.array([[0.001, 0.0], [2.999, 0.0]])\n",
        "        sampling = LHS(xlimits=xlimits)        \n",
        "        x = sampling(self.nx)\n",
        "        xc=torch.tensor(x,dtype=torch.float32)\n",
        "       \n",
        "        xlimits = np.array([[0.0, 0.001], [0.0, 0.999]])\n",
        "        sampling = LHS(xlimits=xlimits)        \n",
        "        y = sampling(self.ny)\n",
        "        yc=torch.tensor(y,dtype=torch.float32)        \n",
        "\n",
        "        xlimits = np.array([[0.0, 0.0], [1.001, 1.999]])\n",
        "        sampling = LHS(xlimits=xlimits)        \n",
        "        x = sampling(self.nx1)\n",
        "        x1=torch.tensor(x,dtype=torch.float32)\n",
        "\n",
        "        xlimits = np.array([[0.0, 0.0], [1.0, 1.999]])\n",
        "        sampling = LHS(xlimits=xlimits)        \n",
        "        y = sampling(self.ny1)\n",
        "        y1=torch.tensor(y,dtype=torch.float32)              \n",
        "\n",
        "        # Domain discretization\n",
        "        self.channel = torch.stack(torch.meshgrid(xc[:,1], yc[:,1])).reshape(2, -1).T\n",
        "        self.channel1 = torch.stack(torch.meshgrid(x1[:,1], y1[:,1])).reshape(2, -1).T\n",
        "        \n",
        "        self.tm = torch.cat([self.channel, self.channel1])             \n",
        "        \n",
        "        u_inlet = torch.tensor(6*(1-yb)*yb)\n",
        "        v_inlet = torch.zeros(len(self.inlet))\n",
        "\n",
        "        u_inlet1 = torch.tensor(-6*(1-yb)*yb)\n",
        "        v_inlet1 = torch.zeros(len(self.inlet1))\n",
        "\n",
        "        p_outlet = torch.zeros(len(self.outlet))\n",
        "\n",
        "        u_bc = torch.zeros(len(self.bc))\n",
        "        v_bc = torch.zeros(len(self.bc))                \n",
        "\n",
        "        self.uv_inlet = torch.stack((u_inlet, v_inlet)).reshape(2, -1).T\n",
        "        self.uv_inlet1 = torch.stack((u_inlet1, v_inlet1)).reshape(2, -1).T\n",
        "        self.p_outlet = (p_outlet).reshape(1, -1).T\n",
        "\n",
        "        self.uv_bc = torch.stack((u_bc, v_bc)).reshape(2, -1).T     \n",
        "\n",
        "        self.pde_sol=torch.zeros(len(self.tm))        \n",
        "        \n",
        "        self.tm = self.tm.to(device)\n",
        "        self.bc = self.bc.to(device)        \n",
        "        self.inlet = self.inlet.to(device)\n",
        "        self.inlet1 = self.inlet1.to(device)\n",
        "        self.outlet = self.outlet.to(device)\n",
        "        self.uv_inlet = self.uv_inlet.to(device)\n",
        "        self.uv_inlet1 = self.uv_inlet1.to(device)\n",
        "        self.p_outlet = self.p_outlet.to(device)\n",
        "        self.pde_sol = self.pde_sol.to(device)\n",
        "        self.uv_bc = self.uv_bc.to(device)        \n",
        "        self.tm.requires_grad = True\n",
        "        self.bc.requires_grad = True        \n",
        "        self.inlet.requires_grad = True\n",
        "        self.inlet1.requires_grad = True\n",
        "        self.outlet.requires_grad = True\n",
        "        \n",
        "        self.criterion = torch.nn.MSELoss()\n",
        "        self.iter = 1\n",
        "        \n",
        "        self.optimizer = torch.optim.LBFGS(\n",
        "            self.model.parameters(), \n",
        "            lr=0.001, \n",
        "            max_iter=100000, \n",
        "            max_eval=100000, \n",
        "            history_size=50,\n",
        "            tolerance_grad=1e-5, \n",
        "            tolerance_change=1.0 * np.finfo(float).eps\n",
        "            )\n",
        "        \n",
        "        self.adam = torch.optim.Adam(self.model.parameters(), lr=0.0015)\n",
        "        \n",
        "    #Definition of Bounday and Navier-stokes residual loss   \n",
        "    def loss_func(self):\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        y_inlet = self.model(self.inlet)\n",
        "        dpsi_dX = torch.autograd.grad(inputs=self.inlet, outputs=y_inlet[:,0], grad_outputs=torch.ones_like(y_inlet[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dx = -1*dpsi_dX[:, 0] \n",
        "        dpsi_dy = dpsi_dX[:, 1]    \n",
        "        \n",
        "        loss_inlet = self.criterion(dpsi_dy, self.uv_inlet[:,0])+self.criterion(dpsi_dx, self.uv_inlet[:,1])\n",
        "\n",
        "        y_inlet1 = self.model(self.inlet1)\n",
        "        \n",
        "        dpsi_dX = torch.autograd.grad(inputs=self.inlet1, outputs=y_inlet1[:,0], grad_outputs=torch.ones_like(y_inlet1[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dx = -1*dpsi_dX[:, 0] \n",
        "        dpsi_dy = dpsi_dX[:, 1]      \n",
        "        \n",
        "        loss_inlet1 = self.criterion(dpsi_dy, self.uv_inlet1[:,0])+self.criterion(dpsi_dx, self.uv_inlet1[:,1])   \n",
        "            \n",
        "        y_bc = self.model(self.bc)\n",
        "        \n",
        "        dpsi_dX = torch.autograd.grad(inputs=self.bc, outputs=y_bc[:,0], grad_outputs=torch.ones_like(y_bc[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dx = -1*dpsi_dX[:, 0] \n",
        "        dpsi_dy = dpsi_dX[:, 1]\n",
        "\n",
        "        loss_bc = self.criterion(dpsi_dy, self.uv_bc[:,0])+self.criterion(dpsi_dx, self.uv_bc[:,1])\n",
        "        y_outlet = self.model(self.outlet)            \n",
        "\n",
        "        loss_outlet = self.criterion(y_outlet[:,1], self.p_outlet)\n",
        "        \n",
        "        loss_b=loss_inlet+loss_inlet1+loss_bc+loss_outlet\n",
        "\n",
        "        y_id = self.model(self.tm)\n",
        "\n",
        "        dpsi_dX = torch.autograd.grad(inputs=self.tm, outputs=y_id[:,0], grad_outputs=torch.ones_like(y_id[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dx = -1*dpsi_dX[:, 0] \n",
        "        dpsi_dy = dpsi_dX[:, 1]\n",
        "        dpsi_dXX = torch.autograd.grad(inputs=self.tm, outputs=dpsi_dy, grad_outputs=torch.ones_like(dpsi_dy), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dyx = dpsi_dXX[:, 0] \n",
        "        dpsi_dyy = dpsi_dXX[:, 1]\n",
        "        dpsi_dYY = torch.autograd.grad(inputs=self.tm, outputs=dpsi_dx, grad_outputs=torch.ones_like(dpsi_dx), retain_graph=True, create_graph=True)[0]\n",
        "        dpsi_dxx = dpsi_dYY[:, 0] \n",
        "        dpsi_dxy = dpsi_dYY[:, 1]\n",
        "        dsxx_dX = torch.autograd.grad(inputs=self.tm, outputs=y_id[:,2], grad_outputs=torch.ones_like(y_id[:,2]), retain_graph=True, create_graph=True)[0]\n",
        "        dsxx_dx = dsxx_dX[:,0]\n",
        "        dsyy_dX = torch.autograd.grad(inputs=self.tm, outputs=y_id[:,3], grad_outputs=torch.ones_like(y_id[:,3]), retain_graph=True, create_graph=True)[0]\n",
        "        dsyy_dy = dsyy_dX[:,1]\n",
        "        dsxy_dX = torch.autograd.grad(inputs=self.tm, outputs=y_id[:,4], grad_outputs=torch.ones_like(y_id[:,4]), retain_graph=True, create_graph=True)[0]\n",
        "        dsxy_dx = dsxy_dX[:, 0] \n",
        "        dsxy_dy = dsxy_dX[:, 1]       \n",
        "\n",
        "        loss_u =  self.rho*(dpsi_dy*dpsi_dyx+dpsi_dx*dpsi_dyy)-dsxx_dx-dsxy_dy\n",
        "        loss_v =  self.rho*(dpsi_dy*dpsi_dxx+dpsi_dx*dpsi_dxy)-dsxy_dx-dsyy_dy\n",
        "        loss_m =  -1*y_id[:,1]+2*self.mu*(dpsi_dyx+dpsi_dxy)-(y_id[:,2]+y_id[:,3])/2+self.mu*(dpsi_dyy+dpsi_dxx)-y_id[:,4]   \n",
        "\n",
        "        loss_ns = self.criterion(loss_u+loss_v+loss_m, self.pde_sol)\n",
        "        b=1.8\n",
        "        loss = b*loss_b+loss_ns \n",
        "        loss.backward()\n",
        "        if self.iter % 1000 == 0: \n",
        "            print(self.iter, loss.item())\n",
        "\n",
        "        self.iter = self.iter + 1        \n",
        "        return loss\n",
        "    \n",
        "    def train(self):\n",
        "        for i in range(20000):\n",
        "            self.adam.step(self.loss_func)\n",
        "        self.optimizer.step(self.loss_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoEiWw6ahhRu",
        "outputId": "d107f17a-40a6-43b5-e187-2997dd8b2106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000 0.0861930325627327\n",
            "tensor([0.2701, 0.2911, 0.3128, 0.3352, 0.3584, 0.3823, 0.4071, 0.4326, 0.4590,\n",
            "        0.4863, 0.5144, 0.5434, 0.5733, 0.6041, 0.6358, 0.6685, 0.7021, 0.7367,\n",
            "        0.7722, 0.8087], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "2000 0.026446877047419548\n",
            "tensor([1.3743, 1.4532, 1.5345, 1.6183, 1.7044, 1.7927, 1.8832, 1.9757, 2.0699,\n",
            "        2.1659, 2.2632, 2.3618, 2.4614, 2.5617, 2.6623, 2.7632, 2.8638, 2.9639,\n",
            "        3.0631, 3.1610], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "3000 0.015414269641041756\n",
            "tensor([3.0057, 3.0972, 3.1867, 3.2741, 3.3592, 3.4417, 3.5217, 3.5988, 3.6729,\n",
            "        3.7440, 3.8118, 3.8761, 3.9368, 3.9937, 4.0466, 4.0953, 4.1396, 4.1793,\n",
            "        4.2142, 4.2442], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "4000 0.006711466703563929\n",
            "tensor([3.0899, 3.1769, 3.2619, 3.3447, 3.4252, 3.5033, 3.5790, 3.6522, 3.7227,\n",
            "        3.7904, 3.8553, 3.9171, 3.9757, 4.0310, 4.0828, 4.1307, 4.1748, 4.2147,\n",
            "        4.2502, 4.2811], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "5000 0.003885033540427685\n",
            "tensor([2.9916, 3.0736, 3.1536, 3.2316, 3.3073, 3.3809, 3.4523, 3.5213, 3.5880,\n",
            "        3.6523, 3.7141, 3.7732, 3.8296, 3.8832, 3.9337, 3.9811, 4.0252, 4.0657,\n",
            "        4.1026, 4.1356], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "6000 0.0025457399897277355\n",
            "tensor([2.7489, 2.8286, 2.9061, 2.9814, 3.0544, 3.1251, 3.1934, 3.2594, 3.3229,\n",
            "        3.3839, 3.4425, 3.4985, 3.5518, 3.6025, 3.6505, 3.6955, 3.7376, 3.7767,\n",
            "        3.8125, 3.8451], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "7000 0.028005532920360565\n",
            "tensor([2.8302, 2.8995, 2.9662, 3.0303, 3.0918, 3.1508, 3.2072, 3.2611, 3.3124,\n",
            "        3.3611, 3.4071, 3.4505, 3.4912, 3.5291, 3.5641, 3.5963, 3.6255, 3.6517,\n",
            "        3.6748, 3.6946], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "8000 0.0008766566752456129\n",
            "tensor([2.7035, 2.7739, 2.8414, 2.9059, 2.9674, 3.0260, 3.0817, 3.1346, 3.1846,\n",
            "        3.2319, 3.2764, 3.3181, 3.3570, 3.3932, 3.4266, 3.4572, 3.4850, 3.5099,\n",
            "        3.5320, 3.5512], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "9000 0.0007666172459721565\n",
            "tensor([2.5946, 2.6595, 2.7212, 2.7796, 2.8349, 2.8871, 2.9362, 2.9825, 3.0258,\n",
            "        3.0663, 3.1041, 3.1391, 3.1715, 3.2012, 3.2283, 3.2528, 3.2748, 3.2941,\n",
            "        3.3109, 3.3252], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "10000 0.0008590526995249093\n",
            "tensor([2.4635, 2.5279, 2.5887, 2.6462, 2.7003, 2.7511, 2.7988, 2.8434, 2.8850,\n",
            "        2.9238, 2.9598, 2.9930, 3.0236, 3.0516, 3.0771, 3.1001, 3.1207, 3.1388,\n",
            "        3.1546, 3.1679], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "11000 9.78643074631691e-05\n",
            "tensor([2.2885, 2.3865, 2.4816, 2.5734, 2.6615, 2.7458, 2.8262, 2.9024, 2.9744,\n",
            "        3.0421, 3.1055, 3.1645, 3.2193, 3.2697, 3.3158, 3.3577, 3.3954, 3.4290,\n",
            "        3.4584, 3.4839], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "12000 3.60804951924365e-05\n",
            "tensor([2.1103, 2.2132, 2.3140, 2.4125, 2.5081, 2.6005, 2.6894, 2.7745, 2.8556,\n",
            "        2.9324, 3.0049, 3.0730, 3.1365, 3.1954, 3.2497, 3.2995, 3.3446, 3.3853,\n",
            "        3.4216, 3.4535], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "13000 2.1799642127007246e-05\n",
            "tensor([1.8362, 1.9326, 2.0282, 2.1227, 2.2156, 2.3066, 2.3952, 2.4813, 2.5644,\n",
            "        2.6444, 2.7209, 2.7939, 2.8631, 2.9284, 2.9897, 3.0469, 3.1001, 3.1491,\n",
            "        3.1939, 3.2347], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "14000 1.350127422483638e-05\n",
            "tensor([1.7172, 1.8116, 1.9058, 1.9996, 2.0926, 2.1844, 2.2745, 2.3626, 2.4484,\n",
            "        2.5316, 2.6119, 2.6890, 2.7628, 2.8329, 2.8993, 2.9618, 3.0202, 3.0746,\n",
            "        3.1249, 3.1710], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "15000 9.894937647914048e-06\n",
            "tensor([1.6715, 1.7664, 1.8616, 1.9567, 2.0514, 2.1452, 2.2377, 2.3285, 2.4173,\n",
            "        2.5037, 2.5874, 2.6680, 2.7454, 2.8192, 2.8894, 2.9556, 3.0178, 3.0758,\n",
            "        3.1295, 3.1790], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "16000 7.240553713927511e-06\n",
            "tensor([1.6641, 1.7623, 1.8613, 1.9604, 2.0594, 2.1576, 2.2547, 2.3502, 2.4438,\n",
            "        2.5349, 2.6233, 2.7085, 2.7903, 2.8684, 2.9425, 3.0125, 3.0781, 3.1392,\n",
            "        3.1958, 3.2476], device='cuda:0', grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#PINN training\n",
        "net = PINN()\n",
        "net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fkq95us7VPU1",
        "outputId": "edbd63b7-4c00-42ff-9e3b-f68bac5ce6ec"
      },
      "outputs": [],
      "source": [
        "#Saving the trained model\n",
        "torch.save(net, './tm_lhs_8l_0.08m_0.1-0.0001.t7')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctBvQMvDfRmu",
        "outputId": "954ffcef-8d11-4c6e-e3e3-485eb6cfec74"
      },
      "outputs": [],
      "source": [
        "#Post processing for results analysis\n",
        "\n",
        "x = torch.arange(0, 3+0.01 ,0.01 )\n",
        "y = torch.arange(0, 1+0.01 , 0.01)\n",
        "\n",
        "x1 = torch.arange(1, 2+0.01 ,0.01 )\n",
        "y1 = torch.arange(1, 2+0.01 , 0.01)\n",
        "\n",
        "outlet = torch.stack(torch.meshgrid(x[-1], y)).reshape(2, -1).T\n",
        "outlet1 = torch.stack(torch.meshgrid(x1, y1[-1])).reshape(2, -1).T\n",
        "        \n",
        "outlet = torch.cat([outlet, outlet1])\n",
        "\n",
        "outlet = outlet.to(net.outlet.device)\n",
        "\n",
        "outlet.requires_grad = True\n",
        "\n",
        "TM = net.model\n",
        "TM.eval()\n",
        "\n",
        "y_pred = TM(outlet)\n",
        "dpsi_dX = torch.autograd.grad(inputs=outlet, outputs=y_pred[:,0], grad_outputs=torch.ones_like(y_pred[:,0]), retain_graph=True, create_graph=True)[0]\n",
        "dpsi_dX[:, 0] = -1*dpsi_dX[:, 0]  \n",
        "\n",
        "fld=torch.cat([outlet, dpsi_dX ,y_pred], 1)\n",
        "fld=fld.detach().cpu().numpy()\n",
        "\n",
        "np.savetxt('output.txt', fld)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.2rc1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
